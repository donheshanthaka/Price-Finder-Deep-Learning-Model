{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c99d0fa9",
   "metadata": {},
   "source": [
    "# Price Finder Feature Extraction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ac7ea",
   "metadata": {},
   "source": [
    "This notebook contains the development of the CNN image classification model used in the Price Finder API to identify vehicles through images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607dd13f",
   "metadata": {},
   "source": [
    "## A quick run-through of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fa3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_script import walk_through_dir\n",
    "\n",
    "# The path to the images folder that contains the train/test/validate image sets\n",
    "PATH = \"images\"\n",
    "\n",
    "walk_through_dir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a96e2d",
   "metadata": {},
   "source": [
    "## Image preprocessing\n",
    "\n",
    "Image preprocessing is done through converting the downloaded images into rgb color format since there can be instances where images of different types such as png to be automatically saved as jpg through the web scraper used, but in reality they would still contain that extra alpha channel making those images 4-channels. For the model that is developed for the Price Finder API, all the images should be converted in 3-channels. Therefore RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225b495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A script from the helper_script is used to convert the images\n",
    "\n",
    "from helper_script import convert_images_rgb\n",
    "\n",
    "convert_images_rgb(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d6cd4f",
   "metadata": {},
   "source": [
    "## Create the data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6bae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"images/train\"\n",
    "test_dir = \"images/test\"\n",
    "validation_dir = \"images/validate\"\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                batch_size=BATCH_SIZE,\n",
    "                                                                crop_to_aspect_ratio=False)\n",
    "\n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                batch_size=BATCH_SIZE,\n",
    "                                                                shuffle=False,\n",
    "                                                                crop_to_aspect_ratio=False)\n",
    "\n",
    "validation_data = tf.keras.preprocessing.image_dataset_from_directory(validation_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                batch_size=BATCH_SIZE,\n",
    "                                                                shuffle=False,\n",
    "                                                                crop_to_aspect_ratio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355cb930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking out the class names\n",
    "train_data.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6018bcb2",
   "metadata": {},
   "source": [
    "## Building a transfer learning feature extraction model using the Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e301ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
